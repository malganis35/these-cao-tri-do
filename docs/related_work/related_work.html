

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
    <link href="../../_static/logo_Destination-Familles-favicon.png" sizes="512x512" rel="icon" type="image/png">
    <title>Chapter 1: Related work &#8212; Cao Tri DO PhD</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/related_work/related_work';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Bibliography" href="../references/references.html" />
    <link rel="prev" title="Introdution" href="../introduction/introduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">Cao Tri DO PhD</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../contents/Aknowledgement.html">Aknowledgement</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../introduction/introduction.html">Introdution</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">State of the art</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Chapter 1: Related work</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../references/references.html">Bibliography</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tuto Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../sphinx_quickstart/index.html">Sphinx Quick Start</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../sphinx_quickstart/sphinx_quickstart.html">Sphinx Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sphinx_quickstart/sphinx_syntax_tutorial.html">Sphinx Syntax Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sphinx_quickstart/file_organisation.html">Files organisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sphinx_quickstart/mermaid_syntax_demo.html">Illustrate Mermaid Diagrams</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-gitlab"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://gitlab.com/do-favier/these-cao-tri-do" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-gitlab"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://gitlab.com/do-favier/these-cao-tri-do/-/edit/main/docs/related_work/related_work.rst" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/docs/related_work/related_work.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 1: Related work</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-regression">1.1 Classification Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-principle">1.1.1 Machine learning principle</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection-in-supervised-learning">1.1.2 Model selection in supervised learning</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="chapter-1-related-work">
<h1>Chapter 1: Related work<a class="headerlink" href="#chapter-1-related-work" title="Permalink to this heading">#</a></h1>
<div class="toctree-wrapper compound">
</div>
<div class="hint admonition">
<p class="admonition-title">Summary</p>
<p>In this chapter, we recall some concepts of machine learning. First, we review the
principles, the learning framework and the evaluation protocol in supervised learning.
Then, we present the algorithms used in our work: <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbors (<span class="math notranslate nohighlight">\(k\)</span>-NN) and
Support Vector Machines (<cite>svm</cite>).</p>
</div>
<section id="classification-regression">
<h2>1.1 Classification Regression<a class="headerlink" href="#classification-regression" title="Permalink to this heading">#</a></h2>
<p>In this section, we review some terminology used in machine learning. First, we recall the
principle of machine learning. Then, we detail how to design a framework for supervised
learning. After that, we present model evaluation. Finally, we review data normalization.</p>
<section id="machine-learning-principle">
<h3>1.1.1 Machine learning principle<a class="headerlink" href="#machine-learning-principle" title="Permalink to this heading">#</a></h3>
<p>The idea of machine learning (also known as pattern learning or pattern recognition) is to
imitate with algorithms executed on computers, the ability of living beings to learn from
examples. For instance, to teach a child how to read letters, we show him during a training
phase, labeled examples of letters (‘A’, ‘B’, ‘C’, etc.) written in different styles and fonts.
We don’t give him a complete and analytic description of the topology of the characters but
labeled examples. Then, during a testing phase, we want the child to be able to recognize and
to label correctly the letters that have been seen during the training, and also to generalize
to new instances <span id="id1">[<a class="reference internal" href="../references/references.html#id2" title="Jiangyuan Mei, Meizhu Liu, Yuan Fang Wang, and Huijun Gao. Learning a Mahalanobis Distance-Based Dynamic Time Warping Measure for Multivariate Time Series Classification. 2015. doi:10.1109/TCYB.2015.2426723.">MLWG15</a>]</span></p>
<p>Let <span class="math notranslate nohighlight">\(X=\{\textbf{x}_i,y_i\}_{i=1}^n\)</span> be a training set of n vector samples <span class="math notranslate nohighlight">\(\textbf{x}_i \in \mathbb{R}^p\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> their corresponding
labels. The aim of supervised machine learning is to learn a relationship (model) <span class="math notranslate nohighlight">\(f\)</span> between
the samples <span class="math notranslate nohighlight">\(\textbf{x}_i\)</span> and their labels <span class="math notranslate nohighlight">\(y_i\)</span> based on examples <span id="id2">[<a class="reference internal" href="../references/references.html#id131" title="C.M. Bishop. Pattern Recognition and Machine Learning. Volume 4. 2006. ISBN 9780387310732. URL: http://www.library.wisc.edu/selectedtocs/bg0137.pdf, arXiv:0-387-31073-8, doi:10.1117/1.2819119.">Bis06</a>, <a class="reference internal" href="../references/references.html#id71" title="G. Dreyfus, J.-M. Martinez, M. Samuelides, M. B. Gordon, F. Badran, and S. Thiria. Apprentissage Apprentissage statistique. eyrolles edition, 2006. ISBN 9782212114645.">DMS+06</a>, <a class="reference internal" href="../references/references.html#id80" title="R. Duda and P. Hart. Pattern Classification and Scene Analysis. Volume 7. 1973. ISBN 0471223611. URL: http://www.jstor.org/stable/1573081?origin=crossref, doi:10.2307/1573081.">DH73</a>]</span>. After the
training phase based on labeled examples <span class="math notranslate nohighlight">\((\textbf{x}_i,y_i)\)</span>, the model <span class="math notranslate nohighlight">\(f\)</span> has to be able to generalize on
the testing phase, <em>i.e.</em>, to give a correct prediction <span class="math notranslate nohighlight">\(y_j\)</span> for new instances <span class="math notranslate nohighlight">\(\textbf{x}_j\)</span> that haven’t been
seen during the training.</p>
<p>When <span class="math notranslate nohighlight">\(y_i\)</span> are class labels (<em>e.g.</em>, class ‘A’, ‘B’, ‘C’ in the case of child’s reading), learning the
model <span class="math notranslate nohighlight">\(f\)</span> is a classification problem; when <span class="math notranslate nohighlight">\(y_i\)</span> is a continuous value (<em>e.g.</em>, the energy consumption
in a building), learning <span class="math notranslate nohighlight">\(f\)</span> is a regression problem. For both problems, when a part of the
labels <span class="math notranslate nohighlight">\(y_i\)</span> are known and another part of <span class="math notranslate nohighlight">\(y_i\)</span> is unknown during training, learning <span class="math notranslate nohighlight">\(f\)</span> is a semi-
supervised problem <span id="id3">[<a class="reference internal" href="../references/references.html#id122" title="X. Zhu. Semi-Supervised Learning Literature Survey. Sciences-New York, pages 1–59, 2007. URL: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2352{\&amp;}rep=rep1{\&amp;}type=pdf, doi:10.1.1.146.2352.">Zhu07</a>]</span>. Note that when the labels <span class="math notranslate nohighlight">\(y_i\)</span> are totally unknown, learning <span class="math notranslate nohighlight">\(f\)</span>
refers to a clustering problem (unsupervised learning) <span id="id4">[<a class="reference internal" href="../references/references.html#id84" title="M.S. Chen, J. Han, and P.S. Yu. Data mining: An Overview from a Database Perspective. 1996. doi:10.1109/69.553155.">CHY96</a>, <a class="reference internal" href="../references/references.html#id30" title="A.K. Jain, M.N. Murty, and P.J. Flynn. Data clustering: a review. ACM Computing Surveys, 31(3):264–323, 1999. URL: http://portal.acm.org/citation.cfm?doid=331499.331504, arXiv:arXiv:1101.1881v2, doi:10.1145/331499.331504.">JMF99</a>]</span>. Semi-supervised
and unsupervised learning problems are out of the scope of this work.</p>
</section>
<section id="model-selection-in-supervised-learning">
<h3>1.1.2 Model selection in supervised learning<a class="headerlink" href="#model-selection-in-supervised-learning" title="Permalink to this heading">#</a></h3>
<p>A key objective of supervised learning algorithms is to build models $f$ with good generalization
capabilities, <em>i.e.</em>, models f that correctly predict the labels <span class="math notranslate nohighlight">\(y_j\)</span> of new unknown samples <span class="math notranslate nohighlight">\((\textbf{x}_j\)</span>.
There exist two types of errors committed by a classification or regression model $f$: training
error and generalization error. Training error is the error on the training set and generalization
error is the error on the testing set. A good supervised model $f$ must not only
fit the training data $X$ well, it must also accurately classify records it has never seen before
(test set <span class="math notranslate nohighlight">\(X_{Test}\)</span>). In other words, a good model $f$ must have low training error as well as
low generalization error. This is important because a model that fits the training data too
much can have a poorer generalization error than a model with a higher training error. Such
situation is known as model overfitting (<a class="reference internal" href="#overfitting"><span class="std std-numref">Fig. 1</span></a>). In general, the complexity in learning can
be measured through 2 measures: the <strong>information complexity</strong> and the <strong>computational complexity</strong>.
The information complexity concerns the generalization performances of the learner:
how many samples are needed? How much time the learner will take to converge to its optimal
solution? Etc. The computational complexity deals with the computational resources needed
to make a new prediction based on the training data.
In most cases, learning algorithms require to tune some hyper-parameters. A first approach
could consist in trying all the possible combinations of hyper-parameters values and keep the
one with the lowest training error. However, as discussed above, the model with the lowest
training error is not always the one with the best generalization error. To avoid overfitting,
the training set can be divided into 2 sets: a learning and a validation set. Suppose that we
have two hyper-parameters to tune: $C$ and $γ$. We make a grid search for each combination
($C$, $γ$) of the hyper-parameters, that is in this case a 2-dimensional grid (<a class="reference internal" href="#overfitting"><span class="std std-numref">Fig. 1</span></a>). For each
combination (a cell of the grid), the model is learned on the learning set and evaluated on the
validation set. At the end, the hyper-parameters with the lowest error on the validation set are
retained and the model $f$ is learned on all training data using these optimal hyper-parameters.
This process is referred to as the model selection.</p>
<figure class="align-center" id="id6">
<span id="overfitting"></span><a class="reference internal image-reference" href="../../_images/Overfitting.png"><img alt="../../_images/Overfitting.png" src="../../_images/Overfitting.png" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">An example of overfitting in the case of classification. The objective is to separate blue points from red points. Black line shows a classifier $f_1$ with low complexity where as green line illustrates a classifier $f_2$ with high complexity. On training examples (blue and red points), the model $f_2$ separates all the classes perfectly but may lead to poor generalization on new unseen examples. Model $f_1$ is often preferred.</span><a class="headerlink" href="#id6" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>In most cases, learning algorithms require to tune some hyper-parameters. A first approach could
consist in trying all the possible combinations of hyper-parameters values and keep the one with
the lowest training error. However, as discussed above, the model with the lowest training error
is not always the one with the best generalization error. To avoid overfitting, the training set
can be divided into 2 sets: a learning and a validation set. Suppose that we have two hyper-parameters
to tune: $C$ and $γ$. We make a grid search for each combination $(C,γ)$ of the hyper-parameters,
that is in this case a 2-dimensional grid (<a class="reference internal" href="#gridsearch"><span class="std std-numref">Fig. 2</span></a>). For each combination (a cell of
the grid), the model is learned on the learning set and evaluated on the validation set. At the end,
the hyper-parameters with the lowest error on the validation set are retained and the model $f$ is
learned on all training data using these optimal hyper-parameters. This process is referred to as
the <strong>model selection</strong>.</p>
<figure class="align-default" id="id7">
<span id="gridsearch"></span><a class="reference internal image-reference" href="../../_images/GridSearch.png"><img alt="../../_images/GridSearch.png" src="../../_images/GridSearch.png" style="width: 250px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Example of a 2 dimensional grid search for parameters $C$ and $γ$.
It defines a grid where each cell of the grid contains a combination
($C$, $γ$). Each combination is used to learn the model and is evaluated
on the validation set.</span><a class="headerlink" href="#id7" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>An alternative is <strong>cross-validation</strong> with $v$ folds, illustrated in
<a class="reference internal" href="#cross-validation2"><span class="std std-numref">Fig. 3</span></a>. In this approach, we partition the training data into
$v$ equal-sized subsets. The objective is to evaluate the error for each combination of
hyper-parameters. For each run, one fold is chosen for validation, while the $v-1$ remaining
folds are used as the learning set. We repeat the process for each fold, thus $v$ times.
Each fold gives one validation error and thus we obtain $v$ errors. The total error for the
current combination of hyper-parameters is obtained by summing up the errors for all $v$ folds.
When $v=n$, the size of training set, this approach is called leave-one-out or Jackknife.
Each test set contains only one sample. The advantage is that as much data as possible are used
for training. Moreover, the validation sets are exclusive and they cover the entire data set.
The drawback is that it is computationally expensive to repeat the procedure $n$ times. Furthermore,
since each validation set contains only one record, the variance of the estimated performance metric
is usually high. This procedure is often used when $n$, the size of the training set, is small.
There exist other methods such as sub-sampling or bootstrap <span id="id5">[<a class="reference internal" href="../references/references.html#id71" title="G. Dreyfus, J.-M. Martinez, M. Samuelides, M. B. Gordon, F. Badran, and S. Thiria. Apprentissage Apprentissage statistique. eyrolles edition, 2006. ISBN 9782212114645.">DMS+06</a>, <a class="reference internal" href="../references/references.html#id80" title="R. Duda and P. Hart. Pattern Classification and Scene Analysis. Volume 7. 1973. ISBN 0471223611. URL: http://www.jstor.org/stable/1573081?origin=crossref, doi:10.2307/1573081.">DH73</a>]</span>. We only
use cross-validation in our experiments.</p>
<figure class="align-default" id="id8">
<span id="cross-validation2"></span><a class="reference internal image-reference" href="../../_images/Cross_validation2.jpg"><img alt="../../_images/Cross_validation2.jpg" src="../../_images/Cross_validation2.jpg" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">$v$-fold Cross-validation for one combination of parameters. For each of $v$ experiments,
use $v-1$ folds for training and a different fold for Testing, then the training error for
this combination of parameter is the mean of all testing errors. This procedure is
illustrated for $v=4$</span><a class="headerlink" href="#id8" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id9">
<a class="reference internal image-reference" href="../../_images/LearningFramework.png"><img alt="../../_images/LearningFramework.png" src="../../_images/LearningFramework.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">General framework for building a supervised (classification/regression) model. Example with 3 features and 2 classes (‘Yes’ and ‘No’)</span><a class="headerlink" href="#id9" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id10">
<a class="reference internal image-reference" href="../../_images/Dataset.png"><img alt="../../_images/Dataset.png" src="../../_images/Dataset.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">Division of a dataset into 3 datasets: training, test and operational</span><a class="headerlink" href="#id10" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../introduction/introduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introdution</p>
      </div>
    </a>
    <a class="right-next"
       href="../references/references.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bibliography</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-regression">1.1 Classification Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-principle">1.1.1 Machine learning principle</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection-in-supervised-learning">1.1.2 Model selection in supervised learning</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cao Tri DO
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, Cao Tri DO.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>